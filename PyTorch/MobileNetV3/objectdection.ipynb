{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: VOC2012\\VOCtrainval_11-May-2012.tar\n",
      "Extracting VOC2012\\VOCtrainval_11-May-2012.tar to VOC2012\n"
     ]
    }
   ],
   "source": [
    "# Define the VOC2012 dataset directory\n",
    "voc2012_dir = 'VOC2012'\n",
    "voc_dataset = VOCSegmentation(root=voc2012_dir, year='2012', image_set='train', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import urllib\n",
    "from PIL import Image\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"voc2012_labels.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (conv_stem): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNormAct2d(\n",
       "    16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): Hardswish()\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): Identity()\n",
       "        (conv_pwl): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (conv_dw): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Hardsigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): ConvBnAct(\n",
       "        (conv): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "  (conv_head): Conv2d(960, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (act2): Hardswish()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (classifier): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the MobileNetV3 model\n",
    "model = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Index: 0\n",
      "airliner 0.6553478837013245\n",
      "wing 0.13278770446777344\n",
      "aircraft carrier 0.04520115256309509\n",
      "airship 0.030603652819991112\n",
      "warplane 0.029921643435955048\n",
      "Image Index: 1\n",
      "screen 0.4549400210380554\n",
      "desktop computer 0.23285773396492004\n",
      "computer keyboard 0.07801167666912079\n",
      "mouse 0.03563154861330986\n",
      "monitor 0.030770277604460716\n",
      "Image Index: 2\n",
      "Great Dane 0.4239879250526428\n",
      "Staffordshire bullterrier 0.17405590415000916\n",
      "pug 0.044321272522211075\n",
      "Labrador retriever 0.042057767510414124\n",
      "Doberman 0.03423333168029785\n",
      "Image Index: 3\n",
      "crane 0.7668129205703735\n",
      "little blue heron 0.02755310758948326\n",
      "hornbill 0.011200114153325558\n",
      "American egret 0.009406385943293571\n",
      "ostrich 0.005504772998392582\n",
      "Image Index: 4\n",
      "desktop computer 0.2356037199497223\n",
      "screen 0.22198599576950073\n",
      "monitor 0.2142537385225296\n",
      "desk 0.09304556995630264\n",
      "computer keyboard 0.050354622304439545\n",
      "Image Index: 5\n",
      "beer glass 0.3517400324344635\n",
      "goblet 0.23220233619213104\n",
      "red wine 0.11897163838148117\n",
      "wine bottle 0.04255139082670212\n",
      "water bottle 0.03156188875436783\n",
      "Image Index: 6\n",
      "catamaran 0.2833681106567383\n",
      "liner 0.14103251695632935\n",
      "trimaran 0.06385257095098495\n",
      "schooner 0.05659271404147148\n",
      "dock 0.037864748388528824\n",
      "Image Index: 7\n",
      "wing 0.4949875771999359\n",
      "warplane 0.2025725543498993\n",
      "airliner 0.07887905091047287\n",
      "space shuttle 0.0719352513551712\n",
      "airship 0.025390909984707832\n",
      "Image Index: 8\n",
      "Granny Smith 0.3469304144382477\n",
      "ladle 0.15517951548099518\n",
      "pineapple 0.12062939256429672\n",
      "maraca 0.027825327590107918\n",
      "fig 0.02195931226015091\n",
      "Image Index: 9\n",
      "airliner 0.8447261452674866\n",
      "wing 0.07690556347370148\n",
      "warplane 0.005814510863274336\n",
      "airship 0.0014228078071027994\n",
      "space shuttle 0.001267947955057025\n",
      "Image Index: 10\n",
      "electric locomotive 0.5910516977310181\n",
      "freight car 0.14603719115257263\n",
      "passenger car 0.09044219553470612\n",
      "steam locomotive 0.07766835391521454\n",
      "streetcar 0.004736121278256178\n",
      "Image Index: 11\n",
      "lorikeet 0.668816089630127\n",
      "bee eater 0.08464454114437103\n",
      "macaw 0.07939381152391434\n",
      "jacamar 0.006920014973729849\n",
      "house finch 0.0030216160230338573\n",
      "Image Index: 12\n",
      "moped 0.4739980399608612\n",
      "motor scooter 0.33701977133750916\n",
      "crash helmet 0.01915048435330391\n",
      "disk brake 0.014454923570156097\n",
      "snowmobile 0.004665127489715815\n",
      "Image Index: 13\n",
      "sorrel 0.3655104339122772\n",
      "horse cart 0.2956121861934662\n",
      "barrel 0.03949589282274246\n",
      "shield 0.014060585759580135\n",
      "cowboy hat 0.012688460759818554\n",
      "Image Index: 14\n",
      "warplane 0.4483278691768646\n",
      "aircraft carrier 0.07043077796697617\n",
      "projectile 0.03535429760813713\n",
      "stretcher 0.031192874535918236\n",
      "bulletproof vest 0.015452610328793526\n",
      "Image Index: 15\n",
      "water buffalo 0.0981544703245163\n",
      "bubble 0.050072744488716125\n",
      "ox 0.04325206205248833\n",
      "paintbrush 0.0364682674407959\n",
      "ice bear 0.032633550465106964\n",
      "Image Index: 16\n",
      "coil 0.23556062579154968\n",
      "park bench 0.21374203264713287\n",
      "bannister 0.1376907378435135\n",
      "sundial 0.05906178802251816\n",
      "rocking chair 0.0419953428208828\n",
      "Image Index: 17\n",
      "tabby 0.2037246823310852\n",
      "Egyptian cat 0.16738592088222504\n",
      "tiger cat 0.03707253187894821\n",
      "lynx 0.027208205312490463\n",
      "Norwegian elkhound 0.023468108847737312\n",
      "Image Index: 18\n",
      "Egyptian cat 0.6755480766296387\n",
      "tabby 0.07231006771326065\n",
      "Siamese cat 0.060291413217782974\n",
      "tiger cat 0.016752861440181732\n",
      "lynx 0.01197193656116724\n",
      "Image Index: 19\n",
      "mountain bike 0.4208141267299652\n",
      "moped 0.14454475045204163\n",
      "tricycle 0.04368048533797264\n",
      "bicycle-built-for-two 0.03390996903181076\n",
      "disk brake 0.013856610283255577\n",
      "Image Index: 20\n",
      "goldfinch 0.4888310730457306\n",
      "lorikeet 0.16493777930736542\n",
      "house finch 0.03203098848462105\n",
      "macaw 0.02592647634446621\n",
      "indigo bunting 0.01036748941987753\n",
      "Image Index: 21\n",
      "passenger car 0.4532586932182312\n",
      "minibus 0.23678937554359436\n",
      "trolleybus 0.17191769182682037\n",
      "limousine 0.006356494966894388\n",
      "fire engine 0.00525367446243763\n",
      "Image Index: 22\n",
      "canoe 0.6795340776443481\n",
      "paddle 0.17843075096607208\n",
      "gondola 0.01245482824742794\n",
      "lakeside 0.011743736453354359\n",
      "tub 0.009011979214847088\n",
      "Image Index: 23\n",
      "Brittany spaniel 0.30841219425201416\n",
      "Blenheim spaniel 0.29208847880363464\n",
      "Welsh springer spaniel 0.04988916590809822\n",
      "doormat 0.04071136191487312\n",
      "basset 0.02170923538506031\n",
      "Image Index: 24\n",
      "go-kart 0.17145925760269165\n",
      "lawn mower 0.10113129764795303\n",
      "moped 0.05646977946162224\n",
      "crash helmet 0.03749172389507294\n",
      "mountain bike 0.026634691283106804\n",
      "Image Index: 25\n",
      "airliner 0.9005546569824219\n",
      "wing 0.034081123769283295\n",
      "trailer truck 0.0010533013846725225\n",
      "airship 0.0009393068612553179\n",
      "warplane 0.0007012552814558148\n",
      "Image Index: 26\n",
      "trailer truck 0.3841699957847595\n",
      "passenger car 0.11961086839437485\n",
      "recreational vehicle 0.11447511613368988\n",
      "tow truck 0.07824979722499847\n",
      "trolleybus 0.06936919689178467\n",
      "Image Index: 27\n",
      "tricycle 0.19421914219856262\n",
      "fur coat 0.1409752070903778\n",
      "broom 0.05843644589185715\n",
      "bicycle-built-for-two 0.0542960986495018\n",
      "jinrikisha 0.03221160173416138\n",
      "Image Index: 28\n",
      "motor scooter 0.39227306842803955\n",
      "moped 0.13760963082313538\n",
      "golfcart 0.10552259534597397\n",
      "lawn mower 0.03813248872756958\n",
      "tractor 0.011542084626853466\n",
      "Image Index: 29\n",
      "horse cart 0.09632961452007294\n",
      "fur coat 0.06617213040590286\n",
      "shield 0.05861799046397209\n",
      "bobsled 0.05127698928117752\n",
      "cuirass 0.04329224303364754\n",
      "Image Index: 30\n",
      "Egyptian cat 0.1403616964817047\n",
      "lynx 0.09703951328992844\n",
      "tabby 0.05437129735946655\n",
      "tiger cat 0.048725128173828125\n",
      "Persian cat 0.03486911952495575\n",
      "Image Index: 31\n",
      "water buffalo 0.39024680852890015\n",
      "ram 0.08654672652482986\n",
      "ox 0.0709446594119072\n",
      "bighorn 0.045563291758298874\n",
      "warthog 0.020641878247261047\n",
      "Image Index: 32\n",
      "sliding door 0.3775424361228943\n",
      "patio 0.1307729035615921\n",
      "dining table 0.07689864933490753\n",
      "china cabinet 0.06907529383897781\n",
      "window shade 0.05326807126402855\n",
      "Image Index: 33\n",
      "ox 0.6052993535995483\n",
      "bison 0.05826924741268158\n",
      "llama 0.04503828287124634\n",
      "sorrel 0.02921096608042717\n",
      "oxcart 0.02448851242661476\n",
      "Image Index: 34\n",
      "studio couch 0.25960156321525574\n",
      "quilt 0.2565265893936157\n",
      "four-poster 0.05559515953063965\n",
      "wardrobe 0.03690750151872635\n",
      "sliding door 0.030138470232486725\n",
      "Image Index: 35\n",
      "Pomeranian 0.6524569988250732\n",
      "Shetland sheepdog 0.1618567705154419\n",
      "Persian cat 0.018115881830453873\n",
      "Angora 0.017685843631625175\n",
      "Pembroke 0.013873301446437836\n",
      "Image Index: 36\n",
      "American Staffordshire terrier 0.5987482666969299\n",
      "boxer 0.2160220742225647\n",
      "Staffordshire bullterrier 0.03281071409583092\n",
      "French bulldog 0.01899113319814205\n",
      "Great Dane 0.014213341288268566\n",
      "Image Index: 37\n",
      "pajama 0.26737672090530396\n",
      "teddy 0.14514079689979553\n",
      "Christmas stocking 0.10280933976173401\n",
      "kimono 0.0753883421421051\n",
      "bib 0.0429113544523716\n",
      "Image Index: 38\n",
      "Italian greyhound 0.4607263505458832\n",
      "whippet 0.2020946592092514\n",
      "Weimaraner 0.06311261653900146\n",
      "Boston bull 0.03141183778643608\n",
      "American Staffordshire terrier 0.026343198493123055\n",
      "Image Index: 39\n",
      "ram 0.5363654494285583\n",
      "ice bear 0.055236123502254486\n",
      "African hunting dog 0.015635643154382706\n",
      "llama 0.015254628844559193\n",
      "bighorn 0.00830611027777195\n",
      "Image Index: 40\n",
      "sorrel 0.26368796825408936\n",
      "ox 0.12639163434505463\n",
      "bloodhound 0.0695265457034111\n",
      "oxcart 0.04849792644381523\n",
      "Arabian camel 0.04625602066516876\n",
      "Image Index: 41\n",
      "dining table 0.4646476209163666\n",
      "window shade 0.08925207704305649\n",
      "china cabinet 0.07833955436944962\n",
      "shoji 0.024658098816871643\n",
      "swab 0.02374267578125\n",
      "Image Index: 42\n",
      "breakwater 0.25500088930130005\n",
      "submarine 0.12639541923999786\n",
      "speedboat 0.12362387031316757\n",
      "seashore 0.06279662251472473\n",
      "promontory 0.041844435036182404\n",
      "Image Index: 43\n",
      "trolleybus 0.8833569288253784\n",
      "passenger car 0.03517485782504082\n",
      "minibus 0.005258303135633469\n",
      "cab 0.003520091762766242\n",
      "beach wagon 0.0016134491888806224\n",
      "Image Index: 44\n",
      "beer glass 0.3827064037322998\n",
      "cocktail shaker 0.14271177351474762\n",
      "bucket 0.0951584205031395\n",
      "measuring cup 0.08474811911582947\n",
      "eggnog 0.033007245510816574\n",
      "Image Index: 45\n",
      "plate 0.7293336987495422\n",
      "dining table 0.15239672362804413\n",
      "restaurant 0.05156397074460983\n",
      "burrito 0.01288941316306591\n",
      "trifle 0.011288613080978394\n",
      "Image Index: 46\n",
      "speedboat 0.5563264489173889\n",
      "fireboat 0.10467009246349335\n",
      "trimaran 0.08598148822784424\n",
      "limousine 0.03159792721271515\n",
      "convertible 0.018527235835790634\n",
      "Image Index: 47\n",
      "desktop computer 0.27810388803482056\n",
      "mouse 0.18445535004138947\n",
      "screen 0.12936651706695557\n",
      "monitor 0.08236822485923767\n",
      "notebook 0.07634681463241577\n",
      "Image Index: 48\n",
      "mountain bike 0.7352936863899231\n",
      "crash helmet 0.06469223648309708\n",
      "moped 0.06313382834196091\n",
      "unicycle 0.014850861392915249\n",
      "bicycle-built-for-two 0.00700476486235857\n",
      "Image Index: 49\n",
      "muzzle 0.06546294689178467\n",
      "patas 0.04662657901644707\n",
      "malinois 0.03959188610315323\n",
      "proboscis monkey 0.03432995826005936\n",
      "llama 0.030684294179081917\n",
      "Image Index: 50\n",
      "Irish setter 0.1132884994149208\n",
      "llama 0.0964798852801323\n",
      "bison 0.07576379925012589\n",
      "ox 0.06406401097774506\n",
      "Chesapeake Bay retriever 0.046992793679237366\n",
      "Image Index: 51\n",
      "quilt 0.1744469702243805\n",
      "Eskimo dog 0.057052381336688995\n",
      "Siberian husky 0.04380005970597267\n",
      "Egyptian cat 0.039379339665174484\n",
      "sleeping bag 0.02612520568072796\n",
      "Image Index: 52\n",
      "dining table 0.659456193447113\n",
      "pedestal 0.08768133819103241\n",
      "desk 0.07279368489980698\n",
      "table lamp 0.010125305503606796\n",
      "folding chair 0.008947083726525307\n",
      "Image Index: 53\n",
      "convertible 0.3430962860584259\n",
      "car wheel 0.16354258358478546\n",
      "limousine 0.16017495095729828\n",
      "sports car 0.06333241611719131\n",
      "beach wagon 0.028286270797252655\n",
      "Image Index: 54\n",
      "hog 0.24840717017650604\n",
      "Indian elephant 0.19825021922588348\n",
      "hippopotamus 0.06708330661058426\n",
      "planetarium 0.03747762739658356\n",
      "fountain 0.033276885747909546\n",
      "Image Index: 55\n",
      "studio couch 0.14434513449668884\n",
      "window shade 0.10065686702728271\n",
      "wall clock 0.09080391377210617\n",
      "table lamp 0.07147902995347977\n",
      "quilt 0.04551894962787628\n",
      "Image Index: 56\n",
      "water buffalo 0.36712226271629333\n",
      "ox 0.15003906190395355\n",
      "bison 0.09788502752780914\n",
      "alp 0.042100146412849426\n",
      "oxcart 0.03679971769452095\n",
      "Image Index: 57\n",
      "ox 0.34194132685661316\n",
      "whippet 0.03560100868344307\n",
      "ram 0.031467195600271225\n",
      "oxcart 0.02532862313091755\n",
      "warthog 0.0232114065438509\n",
      "Image Index: 58\n",
      "minibus 0.5582777261734009\n",
      "passenger car 0.2697611153125763\n",
      "streetcar 0.03525339439511299\n",
      "trolleybus 0.02557244524359703\n",
      "recreational vehicle 0.009108606725931168\n",
      "Image Index: 59\n",
      "greenhouse 0.5960155129432678\n",
      "grocery store 0.10147643834352493\n",
      "restaurant 0.01838778704404831\n",
      "toyshop 0.01438091415911913\n",
      "confectionery 0.010920164175331593\n",
      "Image Index: 60\n",
      "ox 0.48404502868652344\n",
      "ram 0.10865746438503265\n",
      "water buffalo 0.046792685985565186\n",
      "oxcart 0.012731943279504776\n",
      "bighorn 0.010874065570533276\n",
      "Image Index: 61\n",
      "airliner 0.5411897897720337\n",
      "wing 0.27592939138412476\n",
      "warplane 0.04830707237124443\n",
      "aircraft carrier 0.02187245711684227\n",
      "projectile 0.0061956411227583885\n",
      "Image Index: 62\n",
      "crash helmet 0.5591796040534973\n",
      "motor scooter 0.15387891232967377\n",
      "moped 0.0329432412981987\n",
      "disk brake 0.016159556806087494\n",
      "backpack 0.011350838467478752\n",
      "Image Index: 63\n",
      "flagpole 0.09789549559354782\n",
      "pedestal 0.08468639105558395\n",
      "traffic light 0.07545492798089981\n",
      "bell cote 0.048844389617443085\n",
      "analog clock 0.04508080333471298\n",
      "Image Index: 64\n",
      "diaper 0.33446943759918213\n",
      "Band Aid 0.0747738778591156\n",
      "quilt 0.06497545540332794\n",
      "sleeping bag 0.03311992809176445\n",
      "neck brace 0.029443558305501938\n",
      "Image Index: 65\n",
      "bakery 0.121317058801651\n",
      "tobacco shop 0.0989687517285347\n",
      "restaurant 0.0962403416633606\n",
      "wooden spoon 0.07910715043544769\n",
      "shoe shop 0.044065169990062714\n",
      "Image Index: 66\n",
      "warplane 0.32957711815834045\n",
      "wing 0.28949177265167236\n",
      "projectile 0.0739251896739006\n",
      "aircraft carrier 0.04000519961118698\n",
      "submarine 0.02456958405673504\n",
      "Image Index: 67\n",
      "king penguin 0.11004488170146942\n",
      "drake 0.06628585606813431\n",
      "junco 0.06289605796337128\n",
      "goose 0.04171571880578995\n",
      "Italian greyhound 0.0394870825111866\n",
      "Image Index: 68\n",
      "minibus 0.30771514773368835\n",
      "trolleybus 0.2859775424003601\n",
      "passenger car 0.2608030438423157\n",
      "recreational vehicle 0.03429775312542915\n",
      "minivan 0.010690160095691681\n",
      "Image Index: 69\n",
      "mountain bike 0.9198675751686096\n",
      "disk brake 0.019493645057082176\n",
      "moped 0.008896716870367527\n",
      "bicycle-built-for-two 0.0020226386841386557\n",
      "unicycle 0.0015920957084745169\n",
      "Image Index: 70\n",
      "speedboat 0.5349987149238586\n",
      "liner 0.16686175763607025\n",
      "catamaran 0.04870085045695305\n",
      "lakeside 0.012350496836006641\n",
      "dock 0.011285931803286076\n",
      "Image Index: 71\n",
      "pole 0.17358767986297607\n",
      "German shepherd 0.16391749680042267\n",
      "Cardigan 0.10211025923490524\n",
      "worm fence 0.059010520577430725\n",
      "parallel bars 0.029386291280388832\n",
      "Image Index: 72\n",
      "beach wagon 0.6317808628082275\n",
      "pickup 0.08490683883428574\n",
      "minivan 0.06151557341217995\n",
      "cab 0.024059606716036797\n",
      "jeep 0.01889919489622116\n",
      "Image Index: 73\n",
      "sunglass 0.3982956111431122\n",
      "sunscreen 0.1583331674337387\n",
      "sunglasses 0.11848161369562149\n",
      "bikini 0.08689256757497787\n",
      "sandbar 0.0727338194847107\n",
      "Image Index: 74\n",
      "table lamp 0.15815210342407227\n",
      "dining table 0.08465396612882614\n",
      "window shade 0.06371524184942245\n",
      "vase 0.031778257340192795\n",
      "pot 0.028433693572878838\n",
      "Image Index: 75\n",
      "dining table 0.38104286789894104\n",
      "desk 0.1146392822265625\n",
      "china cabinet 0.10351523011922836\n",
      "sliding door 0.03106272965669632\n",
      "carton 0.028110086917877197\n",
      "Image Index: 76\n",
      "garbage truck 0.22297562658786774\n",
      "trailer truck 0.18150313198566437\n",
      "moving van 0.18004721403121948\n",
      "recreational vehicle 0.14256340265274048\n",
      "mobile home 0.04774797707796097\n",
      "Image Index: 77\n",
      "paddle 0.15720444917678833\n",
      "breakwater 0.07799511402845383\n",
      "yawl 0.03884324058890343\n",
      "pelican 0.03617885708808899\n",
      "dock 0.03061521053314209\n",
      "Image Index: 78\n",
      "cliff 0.19612494111061096\n",
      "container ship 0.18664154410362244\n",
      "promontory 0.0720486044883728\n",
      "breakwater 0.025669420138001442\n",
      "valley 0.019097134470939636\n",
      "Image Index: 79\n",
      "moped 0.5143632292747498\n",
      "motor scooter 0.0566832460463047\n",
      "disk brake 0.05257503688335419\n",
      "cowboy hat 0.04172747954726219\n",
      "crutch 0.008531073108315468\n",
      "Image Index: 80\n",
      "diaper 0.14578311145305634\n",
      "maraca 0.11886358261108398\n",
      "bow tie 0.09537181258201599\n",
      "pajama 0.08825979381799698\n",
      "bib 0.043854404240846634\n",
      "Image Index: 81\n",
      "toy terrier 0.13200253248214722\n",
      "Italian greyhound 0.0978466272354126\n",
      "Boston bull 0.060275666415691376\n",
      "miniature pinscher 0.052899520844221115\n",
      "basenji 0.04346180707216263\n",
      "Image Index: 82\n",
      "grand piano 0.2718293070793152\n",
      "harp 0.16425736248493195\n",
      "restaurant 0.042415447533130646\n",
      "accordion 0.03626606985926628\n",
      "cello 0.028132950887084007\n",
      "Image Index: 83\n",
      "beer glass 0.16261574625968933\n",
      "water jug 0.07989741116762161\n",
      "menu 0.05355754494667053\n",
      "restaurant 0.04944713041186333\n",
      "notebook 0.040115538984537125\n",
      "Image Index: 84\n",
      "water buffalo 0.09694710373878479\n",
      "hartebeest 0.07844582945108414\n",
      "plow 0.04142749682068825\n",
      "ox 0.03461877256631851\n",
      "wild boar 0.028268590569496155\n",
      "Image Index: 85\n",
      "tiger cat 0.23522676527500153\n",
      "tabby 0.22886501252651215\n",
      "Egyptian cat 0.08781591802835464\n",
      "computer keyboard 0.034362588077783585\n",
      "paper towel 0.0292961448431015\n",
      "Image Index: 86\n",
      "llama 0.2020125836133957\n",
      "ox 0.10265425592660904\n",
      "Arabian camel 0.09403156489133835\n",
      "bison 0.047776468098163605\n",
      "lion 0.03782180696725845\n",
      "Image Index: 87\n",
      "ox 0.1010848879814148\n",
      "bison 0.09727080911397934\n",
      "alp 0.07299605011940002\n",
      "ram 0.0511254221200943\n",
      "Newfoundland 0.02606099843978882\n",
      "Image Index: 88\n",
      "refrigerator 0.27390947937965393\n",
      "cash machine 0.16967208683490753\n",
      "vending machine 0.037434037774801254\n",
      "cinema 0.0345468670129776\n",
      "file 0.030873337760567665\n",
      "Image Index: 89\n",
      "chainlink fence 0.5245612859725952\n",
      "hen 0.09613651782274246\n",
      "African grey 0.0599568746984005\n",
      "chain mail 0.02337966114282608\n",
      "crane 0.015369259752333164\n",
      "Image Index: 90\n",
      "soup bowl 0.23039403557777405\n",
      "cup 0.14065954089164734\n",
      "goblet 0.12385577708482742\n",
      "laptop 0.11485706269741058\n",
      "teapot 0.021696504205465317\n",
      "Image Index: 91\n",
      "lotion 0.12322372943162918\n",
      "water bottle 0.10829638689756393\n",
      "wine bottle 0.09950661659240723\n",
      "desktop computer 0.05948614701628685\n",
      "eggnog 0.056188832968473434\n",
      "Image Index: 92\n",
      "stole 0.12002570182085037\n",
      "miniskirt 0.09856627881526947\n",
      "sliding door 0.06384092569351196\n",
      "fur coat 0.04113731533288956\n",
      "wig 0.02879851870238781\n",
      "Image Index: 93\n",
      "pot 0.4486951529979706\n",
      "greenhouse 0.16839809715747833\n",
      "padlock 0.06860754638910294\n",
      "vase 0.03186522796750069\n",
      "milk can 0.020724423229694366\n",
      "Image Index: 94\n",
      "airliner 0.20651109516620636\n",
      "warplane 0.17922788858413696\n",
      "wing 0.10916838049888611\n",
      "white stork 0.049728136509656906\n",
      "parachute 0.03183664381504059\n",
      "Image Index: 95\n",
      "ping-pong ball 0.24756288528442383\n",
      "albatross 0.12149801105260849\n",
      "ice lolly 0.11318311840295792\n",
      "baseball 0.05204780027270317\n",
      "soccer ball 0.026354489848017693\n",
      "Image Index: 96\n",
      "bullet train 0.1960844099521637\n",
      "streetcar 0.16043850779533386\n",
      "passenger car 0.147026926279068\n",
      "electric locomotive 0.07676923274993896\n",
      "trolleybus 0.04005047678947449\n",
      "Image Index: 97\n",
      "plow 0.13526012003421783\n",
      "Arabian camel 0.10238714516162872\n",
      "oxcart 0.049546755850315094\n",
      "borzoi 0.03868288919329643\n",
      "Saluki 0.038424212485551834\n",
      "Image Index: 98\n",
      "ram 0.9348867535591125\n",
      "kelpie 0.004653362091630697\n",
      "llama 0.003018841380253434\n",
      "wallaby 0.0020624655298888683\n",
      "Ibizan hound 0.0017196870176121593\n",
      "Image Index: 99\n",
      "mortarboard 0.06888311356306076\n",
      "academic gown 0.0355655811727047\n",
      "sweatshirt 0.034465543925762177\n",
      "suit 0.03205473721027374\n",
      "ice lolly 0.026888050138950348\n",
      "Image Index: 100\n",
      "rocking chair 0.5150551199913025\n",
      "ice lolly 0.10025493800640106\n",
      "washer 0.07150378823280334\n",
      "spatula 0.05016360059380531\n",
      "barber chair 0.025432296097278595\n",
      "Image Index: 101\n",
      "Crock Pot 0.09920725971460342\n",
      "toaster 0.06381102651357651\n",
      "beer bottle 0.05561207979917526\n",
      "coffeepot 0.045613083988428116\n",
      "cocktail shaker 0.026553696021437645\n",
      "Image Index: 102\n",
      "dining table 0.8803215622901917\n",
      "china cabinet 0.011615591123700142\n",
      "patio 0.010950377210974693\n",
      "sliding door 0.01051214151084423\n",
      "grand piano 0.00725908949971199\n",
      "Image Index: 103\n",
      "toucan 0.9658427834510803\n",
      "hornbill 0.0038862188812345266\n",
      "king penguin 0.0016571121523156762\n",
      "vulture 0.00046051593380980194\n",
      "macaw 0.00043215902405790985\n",
      "Image Index: 104\n",
      "electric locomotive 0.585956335067749\n",
      "freight car 0.1649053990840912\n",
      "passenger car 0.09887640178203583\n",
      "steam locomotive 0.01751045696437359\n",
      "streetcar 0.00312962313182652\n",
      "Image Index: 105\n",
      "chickadee 0.2314487248659134\n",
      "bulbul 0.16062316298484802\n",
      "hummingbird 0.10218684375286102\n",
      "bee eater 0.05549270287156105\n",
      "junco 0.04450777545571327\n",
      "Image Index: 106\n",
      "wine bottle 0.7189121246337891\n",
      "zucchini 0.03702908754348755\n",
      "red wine 0.029434746131300926\n",
      "pop bottle 0.025945162400603294\n",
      "lotion 0.01929069310426712\n",
      "Image Index: 107\n",
      "studio couch 0.18057075142860413\n",
      "grand piano 0.13790054619312286\n",
      "home theater 0.09460058063268661\n",
      "dining table 0.08039599657058716\n",
      "sliding door 0.08003678917884827\n",
      "Image Index: 108\n",
      "Angora 0.18907387554645538\n",
      "bow tie 0.11878957599401474\n",
      "Egyptian cat 0.10076382756233215\n",
      "Siamese cat 0.07705353945493698\n",
      "lynx 0.05912487953901291\n",
      "Image Index: 109\n",
      "teddy 0.676254391670227\n",
      "bath towel 0.08081348985433578\n",
      "wooden spoon 0.020153751596808434\n",
      "toyshop 0.013660869561135769\n",
      "diaper 0.010743246413767338\n",
      "Image Index: 110\n",
      "lab coat 0.3205454647541046\n",
      "diaper 0.08474461734294891\n",
      "notebook 0.07405022531747818\n",
      "printer 0.04849591478705406\n",
      "photocopier 0.04142023250460625\n",
      "Image Index: 111\n",
      "albatross 0.679087221622467\n",
      "airliner 0.09473609179258347\n",
      "wing 0.0762699544429779\n",
      "warplane 0.0227586030960083\n",
      "kite 0.018897680565714836\n",
      "Image Index: 112\n",
      "bow tie 0.15665847063064575\n",
      "mortarboard 0.07051803171634674\n",
      "wig 0.05865749716758728\n",
      "suit 0.04345403611660004\n",
      "jersey 0.02822498418390751\n",
      "Image Index: 113\n",
      "ram 0.5479635000228882\n",
      "bighorn 0.24397625029087067\n",
      "ibex 0.06094321236014366\n",
      "bison 0.013469723053276539\n",
      "Chesapeake Bay retriever 0.0016088754637166858\n",
      "Image Index: 114\n",
      "Weimaraner 0.8948421478271484\n",
      "Chesapeake Bay retriever 0.007117354776710272\n",
      "Great Dane 0.00304364413022995\n",
      "microwave 0.0018112051766365767\n",
      "refrigerator 0.0014577870024368167\n",
      "Image Index: 115\n",
      "restaurant 0.6856127381324768\n",
      "plate 0.120334692299366\n",
      "dining table 0.057131316512823105\n",
      "tray 0.014665351249277592\n",
      "bakery 0.010002050548791885\n",
      "Image Index: 116\n",
      "passenger car 0.5654815435409546\n",
      "minibus 0.2325805425643921\n",
      "trolleybus 0.06282112747430801\n",
      "school bus 0.037167713046073914\n",
      "recreational vehicle 0.003688153577968478\n",
      "Image Index: 117\n",
      "Egyptian cat 0.6014048457145691\n",
      "tabby 0.3169640302658081\n",
      "tiger cat 0.06757524609565735\n",
      "dumbbell 0.0003380062698852271\n",
      "totem pole 0.00024458172265440226\n",
      "Image Index: 118\n",
      "Persian cat 0.2275899350643158\n",
      "Siberian husky 0.1975211501121521\n",
      "Siamese cat 0.10644549131393433\n",
      "Egyptian cat 0.0946534052491188\n",
      "wood rabbit 0.02716786228120327\n",
      "Image Index: 119\n",
      "beach wagon 0.3633729815483093\n",
      "racer 0.2789969742298126\n",
      "minivan 0.09509287774562836\n",
      "cab 0.03590356186032295\n",
      "sports car 0.029259927570819855\n",
      "Image Index: 120\n",
      "airliner 0.4224007725715637\n",
      "wing 0.37850871682167053\n",
      "warplane 0.14867492020130157\n",
      "ski 0.0052438960410654545\n",
      "space shuttle 0.0036224178038537502\n",
      "Image Index: 121\n",
      "shield 0.17890536785125732\n",
      "Arabian camel 0.17135322093963623\n",
      "horse cart 0.07541307806968689\n",
      "bearskin 0.04173872247338295\n",
      "sorrel 0.03699558600783348\n",
      "Image Index: 122\n",
      "canoe 0.4399833381175995\n",
      "paddle 0.2023792862892151\n",
      "speedboat 0.02806762605905533\n",
      "sandbar 0.014370047487318516\n",
      "snorkel 0.00687298271805048\n",
      "Image Index: 123\n",
      "moped 0.6339154839515686\n",
      "motor scooter 0.16822665929794312\n",
      "disk brake 0.038794975727796555\n",
      "Model T 0.004921430721879005\n",
      "car wheel 0.004473259672522545\n",
      "Image Index: 124\n",
      "warplane 0.6540143489837646\n",
      "wing 0.24965249001979828\n",
      "airliner 0.011404878459870815\n",
      "space shuttle 0.008265158161520958\n",
      "projectile 0.0031120178755372763\n",
      "Image Index: 125\n",
      "minibus 0.24817241728305817\n",
      "ambulance 0.18029487133026123\n",
      "comic book 0.06890687346458435\n",
      "cab 0.0636214092373848\n",
      "moving van 0.061790406703948975\n",
      "Image Index: 126\n",
      "warthog 0.30520790815353394\n",
      "sundial 0.11391915380954742\n",
      "African elephant 0.10419798642396927\n",
      "ibex 0.0647638738155365\n",
      "Weimaraner 0.0404592826962471\n",
      "Image Index: 127\n",
      "library 0.2926546633243561\n",
      "bookcase 0.27645352482795715\n",
      "home theater 0.07504469156265259\n",
      "bookshop 0.03711812198162079\n",
      "entertainment center 0.03424094244837761\n",
      "Image Index: 128\n",
      "king crab 0.2680273652076721\n",
      "neck brace 0.053965166211128235\n",
      "Dungeness crab 0.041920654475688934\n",
      "ear 0.024021396413445473\n",
      "jigsaw puzzle 0.01677623577415943\n",
      "Image Index: 129\n",
      "saltshaker 0.09686975181102753\n",
      "wine bottle 0.09196383506059647\n",
      "cocktail shaker 0.07433121651411057\n",
      "beer glass 0.052296895533800125\n",
      "microphone 0.03938459977507591\n",
      "Image Index: 130\n",
      "castle 0.12451011687517166\n",
      "megalith 0.09273150563240051\n",
      "maze 0.06791279464960098\n",
      "viaduct 0.05188300088047981\n",
      "cliff dwelling 0.05030147731304169\n",
      "Image Index: 131\n",
      "ram 0.7626003623008728\n",
      "llama 0.035309627652168274\n",
      "Samoyed 0.024131281301379204\n",
      "Great Pyrenees 0.016164861619472504\n",
      "white wolf 0.0061639281921088696\n",
      "Image Index: 132\n",
      "airliner 0.9080598950386047\n",
      "wing 0.01333362702280283\n",
      "warplane 0.006708179134875536\n",
      "aircraft carrier 0.0031728832982480526\n",
      "projectile 0.002968867775052786\n",
      "Image Index: 133\n",
      "cocktail shaker 0.4046534299850464\n",
      "hair spray 0.16727331280708313\n",
      "wine bottle 0.09004153311252594\n",
      "beer bottle 0.07957831025123596\n",
      "hand blower 0.04570484533905983\n",
      "Image Index: 134\n",
      "convertible 0.5762743949890137\n",
      "sports car 0.20889773964881897\n",
      "beach wagon 0.02260591648519039\n",
      "car wheel 0.011232792399823666\n",
      "minivan 0.007394461892545223\n",
      "Image Index: 135\n",
      "stone wall 0.08784898370504379\n",
      "Bouvier des Flandres 0.0784214660525322\n",
      "golden retriever 0.06590065360069275\n",
      "Chesapeake Bay retriever 0.0633283406496048\n",
      "ice bear 0.05307719483971596\n",
      "Image Index: 136\n",
      "ox 0.23627927899360657\n",
      "sorrel 0.17690375447273254\n",
      "Arabian camel 0.17614266276359558\n",
      "horse cart 0.029642192646861076\n",
      "oxcart 0.0192446019500494\n",
      "Image Index: 137\n",
      "pier 0.23867997527122498\n",
      "viaduct 0.11602076143026352\n",
      "dome 0.09148364514112473\n",
      "liner 0.09084706008434296\n",
      "mosque 0.05293046683073044\n",
      "Image Index: 138\n",
      "steam locomotive 0.5530810952186584\n",
      "electric locomotive 0.10486769676208496\n",
      "freight car 0.05969730392098427\n",
      "passenger car 0.04158226028084755\n",
      "lumbermill 0.024223070591688156\n",
      "Image Index: 139\n",
      "streetcar 0.4975070655345917\n",
      "trolleybus 0.2044769674539566\n",
      "cinema 0.050393927842378616\n",
      "bakery 0.026592683047056198\n",
      "restaurant 0.025508105754852295\n",
      "Image Index: 140\n",
      "picket fence 0.12632949650287628\n",
      "library 0.12109411507844925\n",
      "bannister 0.10325906425714493\n",
      "patio 0.055388208478689194\n",
      "thatch 0.05140409991145134\n",
      "Image Index: 141\n",
      "ram 0.7118780612945557\n",
      "komondor 0.1586454212665558\n",
      "llama 0.025451961904764175\n",
      "wool 0.0153242452070117\n",
      "kuvasz 0.01348012126982212\n",
      "Image Index: 142\n",
      "jinrikisha 0.30112841725349426\n",
      "tricycle 0.14666229486465454\n",
      "bicycle-built-for-two 0.044812750071287155\n",
      "Model T 0.04048757255077362\n",
      "bookshop 0.035599786788225174\n",
      "Image Index: 143\n",
      "limousine 0.32061612606048584\n",
      "cab 0.11897120624780655\n",
      "parking meter 0.05119174346327782\n",
      "spotlight 0.04224881902337074\n",
      "restaurant 0.04209970310330391\n",
      "Image Index: 144\n",
      "beach wagon 0.32195425033569336\n",
      "minivan 0.29545140266418457\n",
      "car wheel 0.07269909232854843\n",
      "sports car 0.05446117743849754\n",
      "convertible 0.05146241933107376\n",
      "Image Index: 145\n",
      "warplane 0.5880029797554016\n",
      "wing 0.12607014179229736\n",
      "parachute 0.08562170714139938\n",
      "kite 0.016255274415016174\n",
      "airliner 0.01439717411994934\n",
      "Image Index: 146\n",
      "pot 0.7443268895149231\n",
      "picket fence 0.017007526010274887\n",
      "patio 0.016775120049715042\n",
      "greenhouse 0.013108874671161175\n",
      "rocking chair 0.012404807843267918\n",
      "Image Index: 147\n",
      "electric locomotive 0.8358190655708313\n",
      "freight car 0.08391427248716354\n",
      "passenger car 0.04298793897032738\n",
      "steam locomotive 0.0017104761209338903\n",
      "streetcar 0.001199523452669382\n",
      "Image Index: 148\n",
      "airliner 0.8789504170417786\n",
      "wing 0.02152547799050808\n",
      "warplane 0.012997702695429325\n",
      "space shuttle 0.008835870772600174\n",
      "airship 0.0031485999934375286\n",
      "Image Index: 149\n",
      "bassinet 0.2056056708097458\n",
      "tabby 0.09667541086673737\n",
      "handkerchief 0.0726553425192833\n",
      "tiger cat 0.05219974368810654\n",
      "cairn 0.037401869893074036\n",
      "Image Index: 150\n",
      "kite 0.17806380987167358\n",
      "pelican 0.07913339883089066\n",
      "albatross 0.05276135727763176\n",
      "airship 0.04461519420146942\n",
      "white stork 0.038501985371112823\n",
      "Image Index: 151\n",
      "bicycle-built-for-two 0.5033140182495117\n",
      "unicycle 0.1524861603975296\n",
      "alp 0.11558681726455688\n",
      "mountain bike 0.037270694971084595\n",
      "volcano 0.015451832674443722\n",
      "Image Index: 152\n",
      "jigsaw puzzle 0.20062433183193207\n",
      "dining table 0.039150748401880264\n",
      "restaurant 0.03764444217085838\n",
      "potter's wheel 0.03431858867406845\n",
      "plate 0.025842390954494476\n",
      "Image Index: 153\n",
      "muzzle 0.27152833342552185\n",
      "ox 0.09586932510137558\n",
      "llama 0.029975667595863342\n",
      "ram 0.027661876752972603\n",
      "mask 0.027444856241345406\n",
      "Image Index: 154\n",
      "goldfinch 0.5617976188659668\n",
      "brambling 0.06498570740222931\n",
      "bulbul 0.04495452344417572\n",
      "bee eater 0.03522534295916557\n",
      "house finch 0.02070740796625614\n",
      "Image Index: 155\n",
      "cardigan 0.1624811440706253\n",
      "suit 0.09931107610464096\n",
      "bonnet 0.08168128877878189\n",
      "bolo tie 0.03337419778108597\n",
      "stole 0.03155044838786125\n",
      "Image Index: 156\n",
      "desk 0.20093928277492523\n",
      "desktop computer 0.1462472379207611\n",
      "mouse 0.09327271580696106\n",
      "medicine chest 0.07924869656562805\n",
      "screen 0.052744943648576736\n",
      "Image Index: 157\n",
      "toyshop 0.1398780345916748\n",
      "microwave 0.08710134029388428\n",
      "tobacco shop 0.07730908691883087\n",
      "library 0.06884368509054184\n",
      "confectionery 0.042215704917907715\n",
      "Image Index: 158\n",
      "swing 0.8826971054077148\n",
      "umbrella 0.05857790261507034\n",
      "bow 0.007364189717918634\n",
      "tricycle 0.004230961669236422\n",
      "shopping cart 0.004173205234110355\n",
      "Image Index: 159\n",
      "throne 0.139297753572464\n",
      "jinrikisha 0.06221771612763405\n",
      "thresher 0.04193480685353279\n",
      "grand piano 0.032513342797756195\n",
      "Model T 0.02940751053392887\n",
      "Image Index: 160\n",
      "trolleybus 0.885412335395813\n",
      "minibus 0.013420346193015575\n",
      "passenger car 0.008774937130510807\n",
      "minivan 0.0050758738070726395\n",
      "beach wagon 0.002510314341634512\n",
      "Image Index: 161\n",
      "dowitcher 0.18320554494857788\n",
      "redshank 0.09586352109909058\n",
      "limpkin 0.07219953089952469\n",
      "white stork 0.027366749942302704\n",
      "spoonbill 0.01932123489677906\n",
      "Image Index: 162\n",
      "window shade 0.3388453722000122\n",
      "desk 0.1744638979434967\n",
      "home theater 0.14964830875396729\n",
      "tobacco shop 0.04456876590847969\n",
      "bookcase 0.03401460871100426\n",
      "Image Index: 163\n",
      "custard apple 0.4641360342502594\n",
      "banana 0.16745194792747498\n",
      "cucumber 0.03936534747481346\n",
      "jackfruit 0.02365857921540737\n",
      "pineapple 0.01957510970532894\n",
      "Image Index: 164\n",
      "disk brake 0.17540302872657776\n",
      "moped 0.07695460319519043\n",
      "go-kart 0.0589960478246212\n",
      "chain saw 0.05807948857545853\n",
      "snowmobile 0.05030408129096031\n",
      "Image Index: 165\n",
      "electric locomotive 0.492326945066452\n",
      "passenger car 0.2223970592021942\n",
      "streetcar 0.04602385684847832\n",
      "freight car 0.011393250897526741\n",
      "trolleybus 0.004986771382391453\n",
      "Image Index: 166\n",
      "maillot 0.2149868905544281\n",
      "mountain bike 0.15559406578540802\n",
      "bicycle-built-for-two 0.1300150454044342\n",
      "tricycle 0.10566329210996628\n",
      "shopping cart 0.03480855002999306\n",
      "Image Index: 167\n",
      "bicycle-built-for-two 0.3828715682029724\n",
      "mountain bike 0.20303577184677124\n",
      "lawn mower 0.039430949836969376\n",
      "unicycle 0.026166994124650955\n",
      "tricycle 0.009349953383207321\n",
      "Image Index: 168\n",
      "china cabinet 0.3955221176147461\n",
      "bookcase 0.19833135604858398\n",
      "dining table 0.18280108273029327\n",
      "sliding door 0.015294752083718777\n",
      "library 0.01049598678946495\n",
      "Image Index: 169\n",
      "tabby 0.12758848071098328\n",
      "Persian cat 0.07339294254779816\n",
      "Siamese cat 0.06576739996671677\n",
      "tiger cat 0.03401226922869682\n",
      "Egyptian cat 0.03389870747923851\n",
      "Image Index: 170\n",
      "mountain bike 0.28016313910484314\n",
      "crash helmet 0.17144592106342316\n",
      "bicycle-built-for-two 0.040627621114254\n",
      "unicycle 0.03141329437494278\n",
      "tricycle 0.03004124015569687\n",
      "Image Index: 171\n",
      "cello 0.09757301211357117\n",
      "abaya 0.0819687768816948\n",
      "acoustic guitar 0.0581168606877327\n",
      "quill 0.044303324073553085\n",
      "violin 0.04278584197163582\n",
      "Image Index: 172\n",
      "oxcart 0.2806747853755951\n",
      "ox 0.2716994285583496\n",
      "Great Pyrenees 0.05678260326385498\n",
      "llama 0.03040313348174095\n",
      "ram 0.022015556693077087\n",
      "Image Index: 173\n",
      "seat belt 0.1439717561006546\n",
      "plunger 0.08723235130310059\n",
      "wooden spoon 0.07928935438394547\n",
      "spatula 0.06963646411895752\n",
      "paddle 0.06461134552955627\n",
      "Image Index: 174\n",
      "motor scooter 0.3810711205005646\n",
      "moped 0.2106705605983734\n",
      "disk brake 0.05727558583021164\n",
      "crash helmet 0.030755924060940742\n",
      "car wheel 0.013842078857123852\n",
      "Image Index: 175\n",
      "desktop computer 0.2638910710811615\n",
      "monitor 0.23986710608005524\n",
      "desk 0.2100178301334381\n",
      "screen 0.09135478734970093\n",
      "mouse 0.043088361620903015\n",
      "Image Index: 176\n",
      "crash helmet 0.7097525596618652\n",
      "disk brake 0.09313333034515381\n",
      "moped 0.06725136190652847\n",
      "motor scooter 0.03673398494720459\n",
      "backpack 0.004504228476434946\n",
      "Image Index: 177\n",
      "beagle 0.4901586174964905\n",
      "basset 0.08888696134090424\n",
      "Blenheim spaniel 0.07871903479099274\n",
      "magpie 0.037476737052202225\n",
      "goose 0.020466482266783714\n",
      "Image Index: 178\n",
      "crash helmet 0.5739888548851013\n",
      "motor scooter 0.12427812814712524\n",
      "moped 0.03340437635779381\n",
      "go-kart 0.027564669027924538\n",
      "lawn mower 0.010034734383225441\n",
      "Image Index: 179\n",
      "miniskirt 0.09982620924711227\n",
      "jean 0.06386656314134598\n",
      "wig 0.040125779807567596\n",
      "schipperke 0.038861021399497986\n",
      "crutch 0.028680115938186646\n",
      "Image Index: 180\n",
      "wall clock 0.19464708864688873\n",
      "television 0.13903246819972992\n",
      "analog clock 0.056241441518068314\n",
      "desktop computer 0.04285929352045059\n",
      "home theater 0.03749899938702583\n",
      "Image Index: 181\n",
      "ice bear 0.1008206307888031\n",
      "ram 0.05035030469298363\n",
      "llama 0.04803266376256943\n",
      "whippet 0.0461772121489048\n",
      "ox 0.04154294729232788\n",
      "Image Index: 182\n",
      "ram 0.6785321831703186\n",
      "bighorn 0.07825543731451035\n",
      "hog 0.030966509133577347\n",
      "white wolf 0.029611004516482353\n",
      "wild boar 0.02825750969350338\n",
      "Image Index: 183\n",
      "ox 0.1441221982240677\n",
      "llama 0.0545099601149559\n",
      "oxcart 0.04579458013176918\n",
      "Great Dane 0.03820989280939102\n",
      "ram 0.0322214774787426\n",
      "Image Index: 184\n",
      "airliner 0.6571463346481323\n",
      "space shuttle 0.12015733122825623\n",
      "wing 0.029339399188756943\n",
      "liner 0.0064801718108356\n",
      "bullet train 0.005675267428159714\n",
      "Image Index: 185\n",
      "wing 0.14551103115081787\n",
      "speedboat 0.13639584183692932\n",
      "trimaran 0.09567303955554962\n",
      "warplane 0.09243427962064743\n",
      "missile 0.06054772064089775\n",
      "Image Index: 186\n",
      "steam locomotive 0.20686042308807373\n",
      "freight car 0.08319443464279175\n",
      "tow truck 0.03722775727510452\n",
      "trailer truck 0.03240281715989113\n",
      "passenger car 0.025185609236359596\n",
      "Image Index: 187\n",
      "aircraft carrier 0.7807586789131165\n",
      "dock 0.13010844588279724\n",
      "submarine 0.02866133488714695\n",
      "container ship 0.002763683907687664\n",
      "amphibian 0.001441539148800075\n",
      "Image Index: 188\n",
      "Egyptian cat 0.6753645539283752\n",
      "Siamese cat 0.08721806108951569\n",
      "tiger cat 0.06700688600540161\n",
      "lynx 0.054870445281267166\n",
      "tabby 0.027528002858161926\n",
      "Image Index: 189\n",
      "bicycle-built-for-two 0.22812694311141968\n",
      "jinrikisha 0.09399200230836868\n",
      "crutch 0.08120181411504745\n",
      "unicycle 0.047648753970861435\n",
      "tricycle 0.04235783964395523\n",
      "Image Index: 190\n",
      "electric locomotive 0.6262421607971191\n",
      "passenger car 0.29333218932151794\n",
      "streetcar 0.018049830570816994\n",
      "bullet train 0.01104325708001852\n",
      "freight car 0.007325447630137205\n",
      "Image Index: 191\n",
      "dining table 0.14760763943195343\n",
      "Crock Pot 0.10930640995502472\n",
      "iron 0.07496398687362671\n",
      "china cabinet 0.027616320177912712\n",
      "quilt 0.01987644098699093\n",
      "Image Index: 192\n",
      "sorrel 0.9307952523231506\n",
      "barrel 0.014443672262132168\n",
      "ox 0.006378148682415485\n",
      "worm fence 0.0029971941839903593\n",
      "basset 0.002390072913840413\n",
      "Image Index: 193\n",
      "rocking chair 0.14224113523960114\n",
      "folding chair 0.06550374627113342\n",
      "croquet ball 0.04314820095896721\n",
      "custard apple 0.04018247127532959\n",
      "abacus 0.03984884172677994\n",
      "Image Index: 194\n",
      "Dungeness crab 0.14843502640724182\n",
      "mixing bowl 0.139395609498024\n",
      "crayfish 0.09354272484779358\n",
      "Crock Pot 0.07252661883831024\n",
      "American lobster 0.059865858405828476\n",
      "Image Index: 195\n",
      "sandbar 0.42383289337158203\n",
      "seashore 0.35708385705947876\n",
      "promontory 0.017326293513178825\n",
      "Ibizan hound 0.013859106227755547\n",
      "lakeside 0.007674208376556635\n",
      "Image Index: 196\n",
      "studio couch 0.5588148236274719\n",
      "four-poster 0.08816810697317123\n",
      "quilt 0.03651536628603935\n",
      "window shade 0.025440102443099022\n",
      "grand piano 0.021510129794478416\n",
      "Image Index: 197\n",
      "shopping cart 0.5162680149078369\n",
      "bicycle-built-for-two 0.15578261017799377\n",
      "go-kart 0.05276920273900032\n",
      "unicycle 0.04125046357512474\n",
      "crutch 0.011299802921712399\n",
      "Image Index: 198\n",
      "crash helmet 0.3962196409702301\n",
      "moped 0.14900650084018707\n",
      "motor scooter 0.09173496067523956\n",
      "mountain bike 0.015524286776781082\n",
      "disk brake 0.014412225224077702\n",
      "Image Index: 199\n",
      "dining table 0.9160345196723938\n",
      "grand piano 0.01812792755663395\n",
      "window shade 0.008660219609737396\n",
      "china cabinet 0.007399136200547218\n",
      "desk 0.0044028316624462605\n",
      "Image Index: 200\n",
      "bow tie 0.13875174522399902\n",
      "harmonica 0.05424463376402855\n",
      "microphone 0.031911544501781464\n",
      "drumstick 0.028390107676386833\n",
      "spatula 0.0255456380546093\n",
      "Image Index: 201\n",
      "Egyptian cat 0.3117475211620331\n",
      "tiger cat 0.23740917444229126\n",
      "tabby 0.22598417103290558\n",
      "lynx 0.020513247698545456\n",
      "carton 0.0022017157170921564\n",
      "Image Index: 202\n",
      "liner 0.8081979155540466\n",
      "dock 0.037656571716070175\n",
      "fireboat 0.02641916461288929\n",
      "aircraft carrier 0.010278282687067986\n",
      "limousine 0.0053570568561553955\n",
      "Image Index: 203\n",
      "dogsled 0.834698498249054\n",
      "malamute 0.034036342054605484\n",
      "mountain bike 0.03316884487867355\n",
      "Eskimo dog 0.010417305864393711\n",
      "unicycle 0.005113952327519655\n",
      "Image Index: 204\n",
      "yawl 0.25748202204704285\n",
      "schooner 0.18565110862255096\n",
      "trimaran 0.10786736756563187\n",
      "dock 0.07770083099603653\n",
      "drilling platform 0.038680728524923325\n",
      "Image Index: 205\n",
      "cleaver 0.22690939903259277\n",
      "plate 0.14790722727775574\n",
      "butcher shop 0.12046678364276886\n",
      "hot pot 0.06337213516235352\n",
      "restaurant 0.033510975539684296\n",
      "Image Index: 206\n",
      "home theater 0.7804041504859924\n",
      "entertainment center 0.08021138608455658\n",
      "tape player 0.036568451672792435\n",
      "television 0.026756014674901962\n",
      "loudspeaker 0.02237532287836075\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# Pass the image through the model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 11\u001b[0m     output \u001b[39m=\u001b[39m model(input_image)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Perform softmax on the output to get probabilities\u001b[39;00m\n\u001b[0;32m     14\u001b[0m probabilities \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(output[\u001b[39m0\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\timm\\models\\mobilenetv3.py:155\u001b[0m, in \u001b[0;36mMobileNetV3.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 155\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_features(x)\n\u001b[0;32m    156\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_head(x)\n\u001b[0;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\timm\\models\\mobilenetv3.py:140\u001b[0m, in \u001b[0;36mMobileNetV3.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    138\u001b[0m     x \u001b[39m=\u001b[39m checkpoint_seq(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks, x, flatten\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(x)\n\u001b[0;32m    141\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\timm\\models\\_efficientnet_blocks.py:180\u001b[0m, in \u001b[0;36mInvertedResidual.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    179\u001b[0m     shortcut \u001b[39m=\u001b[39m x\n\u001b[1;32m--> 180\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_pw(x)\n\u001b[0;32m    181\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[0;32m    182\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_dw(x)\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\reub\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Process all images in the dataset\n",
    "for image_index in range(len(voc_dataset)):\n",
    "    # Load an image from the dataset\n",
    "    image, _ = voc_dataset[image_index]\n",
    "\n",
    "    # Preprocess the image\n",
    "    input_image = transform(image).unsqueeze(0)  # transform and add batch dimension\n",
    "\n",
    "    # Pass the image through the model\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)\n",
    "\n",
    "    # Perform softmax on the output to get probabilities\n",
    "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "    # Print top categories and probabilities\n",
    "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "    print(f\"Image Index: {image_index}\")\n",
    "    for i in range(top5_prob.size(0)):\n",
    "        print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), 'mobilenetv3_large.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
